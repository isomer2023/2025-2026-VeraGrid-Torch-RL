import os
import glob
import torch
import numpy as np

# ================= é…ç½® =================
DATA_DIR = "./dataset_output_1mv_urban"

import torch
import numpy as np

def safe_torch_load(path: str):

    try:
        from torch.serialization import add_safe_globals
        add_safe_globals([np.core.multiarray._reconstruct])  # å…³é”®ï¼šæ”¾è¡Œè¿™ä¸ªç¬¦å·
        return torch.load(path, weights_only=True, map_location="cpu")
    except Exception as e1:
        print(f"âš ï¸ weights_only=True ä»å¤±è´¥: {e1}")

    return torch.load(path, weights_only=False, map_location="cpu")

# =======================================

def check_static_assets():
    print("ğŸ” [1/3] æ£€æŸ¥é™æ€èµ„äº§ (static_assets.pt)...")
    # 1. è¿™é‡Œå®šä¹‰äº†å˜é‡åæ˜¯ 'path'
    path = os.path.join(DATA_DIR, "static_assets.pt")

    if not os.path.exists(path):
        print(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {path}")
        return None, None

    try:
        # 2. ä¿®æ­£è¿™é‡Œï¼šæŠŠ static_assets_path æ”¹æˆ path
        assets = safe_torch_load(path)

        perm = assets['perm']
        pe = assets['pe']
        n_nodes = assets['num_nodes']

        print(f"   âœ… æ–‡ä»¶åŠ è½½æˆåŠŸ")
        print(f"   - è®°å½•èŠ‚ç‚¹æ•° (N): {n_nodes}")
        print(f"   - RCM ç´¢å¼•é•¿åº¦: {len(perm)}")
        print(f"   - PE å½¢çŠ¶: {pe.shape} (åº”ä¸º [N, 16])")

        # éªŒè¯ RCM ç´¢å¼•æ˜¯å¦æœ‰æ•ˆ
        if len(perm) != n_nodes:
            print(f"âŒ é”™è¯¯: Perm é•¿åº¦ ({len(perm)}) ä¸ N ({n_nodes}) ä¸ä¸€è‡´!")

        # éªŒè¯ PE æ˜¯å¦æœ‰ NaN
        if torch.isnan(pe).any():
            print("âŒ é”™è¯¯: PE ä¸­åŒ…å« NaN!")

        return n_nodes, pe.shape[1]  # è¿”å› N å’Œ PE_dim

    except Exception as e:
        print(f"âŒ è¯»å–å‡ºé”™: {e}")
        # æ‰“å°è¯¦ç»†é”™è¯¯æ ˆï¼Œæ–¹ä¾¿æ’æŸ¥
        import traceback
        traceback.print_exc()
        return None, None


def check_stats():
    print("\nğŸ” [2/3] æ£€æŸ¥ç»Ÿè®¡é‡ (stats.pt)...")
    path = os.path.join(DATA_DIR, "stats.pt")

    if not os.path.exists(path):
        print(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {path}")
        return None, None

    try:
        stats = torch.load(path)
        mean = stats['x_mean']
        std = stats['x_std']

        print(f"   âœ… æ–‡ä»¶åŠ è½½æˆåŠŸ")
        print(f"   - Mean å½¢çŠ¶: {mean.shape} (åº”ä¸º [6])")
        print(f"   - Std  å½¢çŠ¶: {std.shape} (åº”ä¸º [6])")
        print(f"   - Mean æ•°å€¼: {mean.numpy()}")
        print(f"   - Std  æ•°å€¼: {std.numpy()}")

        if torch.isnan(mean).any() or torch.isnan(std).any():
            print("âŒ é”™è¯¯: ç»Ÿè®¡é‡åŒ…å« NaN!")

        if (std == 0).any():
            print("âš ï¸ è­¦å‘Š: æŸäº›ç‰¹å¾çš„ Std ä¸º 0ï¼Œè¿™å¯èƒ½å¯¼è‡´å½’ä¸€åŒ–é™¤é›¶é”™è¯¯ (è®­ç»ƒè„šæœ¬é‡Œéœ€è¦å¤„ç†)ã€‚")

        return mean, std

    except Exception as e:
        print(f"âŒ è¯»å–å‡ºé”™: {e}")
        return None, None


def check_data_chunks(expected_n_nodes):
    print("\nğŸ” [3/3] æ£€æŸ¥æ•°æ®å—æ ·æœ¬ (chunk_*.pt)...")
    files = sorted(glob.glob(os.path.join(DATA_DIR, "chunk_*.pt")))

    if len(files) == 0:
        print("âŒ æ²¡æœ‰æ‰¾åˆ°æ•°æ®å—æ–‡ä»¶ (chunk_*.pt)")
        return

    print(f"   âœ… æ‰¾åˆ° {len(files)} ä¸ªæ•°æ®å—æ–‡ä»¶")

    # åªæ£€æŸ¥ç¬¬ä¸€ä¸ªæ–‡ä»¶ï¼Œé¿å…åˆ·å±
    first_file = files[0]
    print(f"   ğŸ‘‰ æ­£åœ¨æ·±å…¥æ£€æŸ¥ç¬¬ä¸€ä¸ªæ–‡ä»¶: {os.path.basename(first_file)}")

    try:
        samples = torch.load(first_file)
        print(f"   - æ ·æœ¬æ•°é‡: {len(samples)}")

        if len(samples) == 0:
            print("âš ï¸ è­¦å‘Š: æ•°æ®å—æ˜¯ç©ºçš„!")
            return

        # æŠ½å–ç¬¬0ä¸ªæ ·æœ¬è¿›è¡Œè¯¦ç»†è§£å‰–
        sample = samples[0]
        x = sample['x']
        y = sample['y']
        mask = sample['mask']

        print(f"   --- æ ·æœ¬ #0 è¯¦æƒ… ---")
        print(f"   - x shape: {x.shape} (åº”ä¸º [6, {expected_n_nodes}])")
        print(f"   - y shape: {y.shape} (åº”ä¸º [1, {expected_n_nodes}])")
        print(f"   - mask shape: {mask.shape} (åº”ä¸º [{expected_n_nodes}])")

        # 1. ç»´åº¦æ£€æŸ¥
        if x.shape[1] != expected_n_nodes:
            print(f"âŒ è‡´å‘½é”™è¯¯: æ ·æœ¬èŠ‚ç‚¹æ•° ({x.shape[1]}) ä¸é™æ€èµ„äº§ ({expected_n_nodes}) ä¸ä¸€è‡´ï¼è®­ç»ƒå¿…æŒ‚ï¼")

        # 2. æ•°å€¼æ£€æŸ¥
        if torch.isnan(x).any():
            print("âŒ é”™è¯¯: è¾“å…¥ç‰¹å¾ x åŒ…å« NaN")
        if torch.isnan(y).any():
            print("âŒ é”™è¯¯: æ ‡ç­¾ y åŒ…å« NaN")

        # 3. Mask é€»è¾‘æ£€æŸ¥ (Bus 86)
        active_gens = mask.sum().item()
        print(f"   - æœ‰æ•ˆå‘ç”µæœºæ•° (Mask=True): {active_gens}")

        if active_gens == 0:
            print("âš ï¸ è­¦å‘Š: è¯¥æ ·æœ¬æ²¡æœ‰æœ‰æ•ˆçš„å‘ç”µæœº (å…¨æ˜¯ False)ï¼å¯èƒ½æ˜¯è¿‡æ»¤é€»è¾‘å¤ªä¸¥ï¼Œæˆ–è€…æ‰€æœ‰å‘ç”µæœºéƒ½è¢«å…³åœäº†ã€‚")
        else:
            # æ£€æŸ¥ Mask ä¸º True çš„åœ°æ–¹ï¼Œy æ˜¯å¦åœ¨ [0, 1] ä¹‹é—´
            # mask éœ€è¦æ‰©å±•ç»´åº¦æ‰èƒ½ç´¢å¼• y [1, N]
            y_valid = y[0][mask]
            print(f"   - æœ‰æ•ˆ y å€¼ç¤ºä¾‹: {y_valid[:5].numpy()}")
            if (y_valid < 0).any() or (y_valid > 1.0).any():
                print("âš ï¸ è­¦å‘Š: æŸäº›ç›®æ ‡å€¼ y è¶…å‡ºäº† [0, 1] èŒƒå›´ï¼")
            else:
                print("   âœ… ç›®æ ‡å€¼èŒƒå›´æ­£å¸¸ [0, 1]")

        # 4. ç‰¹å¾èŒƒå›´æ£€æŸ¥ (Sanity Check)
        v_mag = x[3, :]  # ç¬¬4è¡Œæ˜¯ç”µå‹å¹…å€¼
        print(f"   - ç”µå‹å¹…å€¼ (x[3]) èŒƒå›´: Min={v_mag.min():.4f}, Max={v_mag.max():.4f}")
        if v_mag.max() > 1.2 or v_mag.min() < 0.8:
            print("âš ï¸ è­¦å‘Š: ç”µå‹å¹…å€¼çœ‹èµ·æ¥æœ‰ç‚¹å¼‚å¸¸ (åç¦» 1.0 å¤ªå¤š)ï¼Œè¯·ç¡®è®¤å•ä½æ˜¯å¦æ­£ç¡®ã€‚")

    except Exception as e:
        print(f"âŒ æ£€æŸ¥æ•°æ®å—æ—¶å‡ºé”™: {e}")
        import traceback
        traceback.print_exc()


def main():
    print("ğŸš‘ å¯åŠ¨æ•°æ®ä½“æ£€ç¨‹åº...\n")

    # 1. æ£€æŸ¥é™æ€èµ„äº§
    n_nodes, pe_dim = check_static_assets()

    if n_nodes is None:
        print("\nğŸš« ä½“æ£€ç»ˆæ­¢ï¼šé™æ€èµ„äº§ç¼ºå¤±ï¼Œæ— æ³•ç»§ç»­æ£€æŸ¥ã€‚")
        return

    # 2. æ£€æŸ¥ç»Ÿè®¡é‡
    check_stats()

    # 3. æ£€æŸ¥æ•°æ®æ ·æœ¬
    check_data_chunks(n_nodes)

    print("\nâœ… ä½“æ£€ç»“æŸã€‚å¦‚æœæ²¡æœ‰çº¢è‰²âŒï¼Œä½ å¯ä»¥æ”¾å¿ƒåœ°å¼€å§‹è®­ç»ƒäº†ï¼")


if __name__ == "__main__":
    main()