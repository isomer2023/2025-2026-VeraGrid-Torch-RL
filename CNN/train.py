import os
import glob
import random
import torch
import torch.nn.functional as F
import torch.optim as optim
import numpy as np
import datetime as dt
import matplotlib.pyplot as plt
from torch.utils.data import Dataset, DataLoader
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score

try:
    from cnn_model import GridCNN
except ImportError:
    print("âŒ ç¼ºå°‘ cnn_model.py")
    exit()

# ================= âš™ï¸ é…ç½® =================
SCRIPT_PATH = os.path.abspath(__file__)
CURRENT_DIR = os.path.dirname(SCRIPT_PATH)
DATA_DIR = os.path.join(CURRENT_DIR, "dataset_output_1MVLV-urban")
SAVE_PATH = os.path.join(CURRENT_DIR, "best_cnn_model_1MVLV-urban.pth")
#get datetime and transfer to yymmdd-hhmmss
datetime = dt.datetime.now().strftime("%y%m%d-%H%M%S")
IMG_SAVE_PATH = os.path.join(CURRENT_DIR, f"result_scatter_{datetime}.png")

LR = 1e-3
EPOCHS = 200  # å¤šè·‘ä¸€ç‚¹ï¼Œç»™ Plateau è°ƒåº¦å™¨æœºä¼š
BATCH_SIZE = 64
HIDDEN_DIM = 256
DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")
SEED = 42
PE_DIM_KEEP = 4  # ğŸ”¥ã€Idea 1ã€‘åªä¿ç•™å‰ 4 ç»´ PE
VOLT_SCALE = 5.0  # ğŸ”¥ã€Idea 3ã€‘ç”µå‹é€šé“æ”¾å¤§å€æ•°
# ==========================================

random.seed(SEED);
torch.manual_seed(SEED)

print(f"ğŸ“‚ å·¥ä½œç›®å½•: {CURRENT_DIR}")

# 1. åŠ è½½èµ„äº§
assets_path = os.path.join(DATA_DIR, "static_assets.pt")
if not os.path.exists(assets_path):
    print("âŒ æ‰¾ä¸åˆ°é™æ€èµ„äº§")
    exit()
assets = torch.load(assets_path, map_location=DEVICE, weights_only=False)
full_pe = assets['pe'].t().to(DEVICE)  # åŸå§‹ [8, N]

# ğŸ”¥ã€Idea 1 å®ç°ã€‘PE é™ç»´ï¼šåªå–å‰ 4 è¡Œ
STATIC_PE = full_pe[:PE_DIM_KEEP, :]
print(f"âœ‚ï¸  PE å·²å‰Šå‡: åŸå§‹ 8 ç»´ -> ä¿ç•™å‰ {PE_DIM_KEEP} ç»´")

stats_path = os.path.join(DATA_DIR, "stats.pt")
if not os.path.exists(stats_path):
    print("âŒ æ‰¾ä¸åˆ°ç»Ÿè®¡é‡")
    exit()
stats = torch.load(stats_path, map_location=DEVICE, weights_only=False)
X_MEAN = stats['x_mean'].to(DEVICE)
X_STD = stats['x_std'].to(DEVICE)
X_STD[X_STD < 1e-6] = 1.0


# 2. æ•°æ®é›†
class GridDataset(Dataset):
    def __init__(self, data_list): self.data = data_list

    def __len__(self): return len(self.data)

    def __getitem__(self, idx): return self.data[idx]


def collate_fn(batch):
    x = torch.stack([item['x'] for item in batch])
    y = torch.stack([item['y'] for item in batch])
    mask = torch.stack([item['mask'] for item in batch])
    return x, y, mask


def load_all_chunks(data_dir):
    files = sorted(glob.glob(os.path.join(data_dir, "chunk_*.pt")))
    all_data = []
    print("ğŸ“‚ è¯»å–æ•°æ®ä¸­...")
    for f in files:
        try:
            all_data.extend(torch.load(f, weights_only=False))
        except:
            pass
    print(f"âœ… åŠ è½½ {len(all_data)} æ ·æœ¬")
    return all_data


# 3. è¯„ä¼°
def evaluate_model(model, loader, device, return_arrays=False):
    model.eval()
    all_true, all_pred = [], []
    with torch.no_grad():
        for x, y, mask in loader:
            x, y, mask = x.to(device), y.to(device), mask.to(device)

            # å½’ä¸€åŒ–
            x_norm = (x - X_MEAN.view(1, -1, 1)) / X_STD.view(1, -1, 1)

            # ğŸ”¥ã€Idea 3 å®ç°ã€‘å¼ºè°ƒç”µå‹é€šé“
            # å‡è®¾é€šé“ 3 æ˜¯ V_magã€‚æˆ‘ä»¬æ‰‹åŠ¨æ”¾å¤§å®ƒçš„æ•°å€¼ã€‚
            # æ­¤æ—¶ x_norm å·²ç»æ˜¯ Mean=0, Std=1 çš„åˆ†å¸ƒã€‚
            # æ”¾å¤§åï¼Œç”µå‹å¼‚å¸¸ç‚¹çš„æ•°å€¼ä¼šå˜å¾—å¾ˆå¤§ï¼ˆæ¯”å¦‚ä» 2.0 å˜æˆ 10.0ï¼‰ï¼Œå¼ºè¿« Loss å…³æ³¨å®ƒã€‚
            x_norm[:, 3, :] = x_norm[:, 3, :] * VOLT_SCALE

            # æ‹¼æ¥ PE (åªæœ‰ 4 ç»´)
            pe_batch = STATIC_PE.unsqueeze(0).expand(x.shape[0], -1, -1)
            x_input = torch.cat([x_norm, pe_batch], dim=1)

            pred = model(x_input)

            if mask.sum() == 0: continue
            valid_pred = pred[mask.unsqueeze(1)]
            valid_true = y[mask.unsqueeze(1)]
            all_pred.append(valid_pred.cpu().numpy())
            all_true.append(valid_true.cpu().numpy())

    if not all_true: return (None,) * 5 if return_arrays else (None,) * 3
    y_t, y_p = np.concatenate(all_true), np.concatenate(all_pred)
    mae = mean_absolute_error(y_t, y_p)
    rmse = np.sqrt(mean_squared_error(y_t, y_p))
    r2 = r2_score(y_t, y_p)
    return (mae, rmse, r2, y_t, y_p) if return_arrays else (mae, rmse, r2)


def main():
    all_data = load_all_chunks(DATA_DIR)
    if not all_data: return
    random.shuffle(all_data)
    cut = int(len(all_data) * 0.8)
    train_dl = DataLoader(GridDataset(all_data[:cut]), batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_fn)
    test_dl = DataLoader(GridDataset(all_data[cut:]), batch_size=BATCH_SIZE, shuffle=False, collate_fn=collate_fn)

    # è®¡ç®—è¾“å…¥é€šé“æ•°
    sample_dim = all_data[0]['x'].shape[0]  # 5
    # è¾“å…¥ = ç‰©ç†(5) + PE(4)
    # (Global çš„ +3 æ˜¯åœ¨ model å†…éƒ¨å¤„ç†çš„ï¼Œè¿™é‡Œä¸éœ€è¦ç®—)
    in_channels = sample_dim + PE_DIM_KEEP

    print(f"ğŸš€ è¾“å…¥ç»´åº¦: {sample_dim} (Phys) + {PE_DIM_KEEP} (PE) = {in_channels}")
    print(f"âš¡ ç”µå‹é€šé“æ”¾å¤§å€æ•°: {VOLT_SCALE}x")

    model = GridCNN(in_channels=in_channels, hidden_dim=HIDDEN_DIM).to(DEVICE)
    optimizer = optim.Adam(model.parameters(), lr=LR)

    # æ¢å›ç¨³å¥çš„è°ƒåº¦å™¨ï¼Œåº”å¯¹é«˜å™ªå£°æ•°æ®
    scheduler = optim.lr_scheduler.ReduceLROnPlateau(
        optimizer, mode='min', factor=0.5, patience=5
    )

    print(f"â„¹ï¸  é…ç½®: Global Feats + Voltage Boost + Reduced PE")
    best_mae = float('inf')

    for epoch in range(1, EPOCHS + 1):
        model.train()
        losses = []
        for x, y, mask in train_dl:
            x, y, mask = x.to(DEVICE), y.to(DEVICE), mask.to(DEVICE)
            optimizer.zero_grad()

            # 1. å½’ä¸€åŒ–
            x_norm = (x - X_MEAN.view(1, -1, 1)) / X_STD.view(1, -1, 1)

            # 2. ğŸ”¥ã€Idea 3ã€‘æ‰‹åŠ¨æ”¾å¤§ç”µå‹ç‰¹å¾
            # é€šé“ 3 æ˜¯ V_magï¼Œæ”¾å¤§å®ƒï¼
            x_norm[:, 3, :] = x_norm[:, 3, :] * VOLT_SCALE

            # 3. æ‹¼æ¥å‰Šå‡åçš„ PE
            pe_batch = STATIC_PE.unsqueeze(0).expand(x.shape[0], -1, -1)
            x_input = torch.cat([x_norm, pe_batch], dim=1)

            # 4. è¿›æ¨¡å‹ (å†…éƒ¨ä¼šè‡ªåŠ¨è®¡ç®— Global Features å¹¶æ‹¼æ¥)
            pred = model(x_input)

            if mask.sum() == 0: continue
            mask_exp = mask.unsqueeze(1)
            loss = F.smooth_l1_loss(pred[mask_exp], y[mask_exp])

            loss.backward()
            optimizer.step()
            losses.append(loss.item())

        avg_loss = np.mean(losses) if losses else 0
        mae, rmse, r2 = evaluate_model(model, test_dl, DEVICE)
        curr_lr = optimizer.param_groups[0]['lr']
        val_str = f"{mae:.6f}" if mae is not None else "nan"

        print(f"{epoch:<6} | Loss:{avg_loss:<8.6f} | MAE:{val_str:<9} | R2:{r2:.4f} | LR:{curr_lr:.1e}")

        if mae is not None:
            scheduler.step(mae)

        if mae is not None and mae < best_mae:
            best_mae = mae
            torch.save(model.state_dict(), SAVE_PATH)

    print("\nğŸ‰ è®­ç»ƒç»“æŸï¼")
    model.load_state_dict(torch.load(SAVE_PATH, map_location=DEVICE, weights_only=True))
    mae, rmse, r2, y_t, y_p = evaluate_model(model, test_dl, DEVICE, True)

    if mae is not None:
        plt.figure(figsize=(8, 8))
        hb = plt.hexbin(y_t, y_p, gridsize=50, mincnt=1, cmap='inferno', bins='log')
        plt.colorbar(hb)
        plt.plot([0, 1], [0, 1], "w--")
        plt.title(f"Voltx{VOLT_SCALE} + Global + PE{PE_DIM_KEEP}\nMAE={mae:.4f}, R2={r2:.4f}")
        plt.savefig(IMG_SAVE_PATH, dpi=300)
        try:
            os.startfile(CURRENT_DIR)
        except:
            pass


if __name__ == "__main__":
    main()