import os
import warnings
from copy import deepcopy
import numpy as np
import torch
from tqdm import tqdm
import simbench as sb

warnings.filterwarnings("ignore")

try:
    import GC_PandaPowerImporter
    from VeraGridEngine import api as gce
except ImportError as e:
    print(f"âŒ ç¼ºå°‘ä¾èµ–: {e}")
    raise

# ================= âš™ï¸ é…ç½® =================
CURRENT_DIR = os.path.dirname(os.path.abspath(__file__))
SAVE_DIR = os.path.join(CURRENT_DIR, "dataset_output_1MVLV-urban")
SB_CODE = "1-MVLV-urban-5.303-0-no_sw"#"1-MV-urban--0-sw"

NUM_SAMPLES = 2000
CHUNK_SIZE = 100

SGEN_POWER_THRESHOLD = 1e-3          # è¿‡æ»¤â€œæ•´å¤©æ²¡å…‰ä¼â€çš„æ—¶åˆ»
SGEN_NODE_THRESHOLD = 1e-4           # å•å°sgenä½äºè¿™ä¸ªï¼Œå°±ä¸å½“ä½œå¯æ§PVèŠ‚ç‚¹ï¼ˆmask=Falseï¼‰
RATE_TIGHTEN_FACTOR = 1.0

# k é‡‡æ ·ï¼ˆé»˜è®¤è¶³å¤Ÿè¦†ç›–ä½ æµ‹å‡ºæ¥çš„ç”µå‹èŒƒå›´ï¼‰
K_GLOBAL_MIN, K_GLOBAL_MAX = 0.4, 3.6
K_LOCAL_MIN, K_LOCAL_MAX = 0.85, 1.15

# åˆ†æ¡¶æ¯”ä¾‹ï¼ˆé»˜è®¤ 40/40/20ï¼‰
USE_BUCKET_SAMPLING = True
BUCKET_TARGET = {"safe": 0.40, "mid": 0.40, "high": 0.20}
V_SAFE = 1.03
V_LIMIT = 1.05

MAX_TRIES_PER_SAMPLE = 200  # é˜²æ­¢æ­»å¾ªç¯

# ==========================================

# åŠ è½½èµ„äº§
ASSETS_PATH = os.path.join(SAVE_DIR, "static_assets.pt")
if not os.path.exists(ASSETS_PATH):
    raise FileNotFoundError("âŒ æ‰¾ä¸åˆ° static_assets.pt")

ASSETS = torch.load(ASSETS_PATH, weights_only=False)
PERM_IDX = ASSETS["perm"]
NUM_NODES = ASSETS["num_nodes"]

# ----------- robust helpers -----------
def _set_val(obj, attr_list, val):
    for a in attr_list:
        try:
            setattr(obj, a, val)
            return True
        except Exception:
            pass
    return False

def _get_val(obj, attr_list, default=None):
    for a in attr_list:
        if hasattr(obj, a):
            try:
                v = getattr(obj, a)
                if v is None:
                    continue
                return v
            except Exception:
                pass
    return default

def _get_float(obj, attr_list, default=0.0):
    v = _get_val(obj, attr_list, None)
    try:
        return float(v)
    except Exception:
        return float(default)

def _is_slack(g):
    return "Ext_Grid" in str(getattr(g, "name", ""))

def _is_sgen(g):
    return "sgen" in str(getattr(g, "name", ""))

def _idx_from_name(name):
    try:
        return int(str(name).split("_")[1])
    except Exception:
        return None

def lock_Q_as_PQ(gen, Q_fixed=0.0):
    _set_val(gen, ["Q", "q"], Q_fixed)
    _set_val(gen, ["Qmin", "qmin_set"], Q_fixed)
    _set_val(gen, ["Qmax", "qmax_set"], Q_fixed)

def tighten_thermal_limits(grid, factor=1.0):
    branches = list(getattr(grid, "lines", [])) + list(getattr(grid, "transformers", []))
    for br in branches:
        old_rate = _get_float(br, ["rate", "Rate"], 100.0)
        _set_val(br, ["rate", "Rate"], old_rate * factor)

def find_slack_bus_idx(grid, bus_idx_map):
    for g in getattr(grid, "generators", []):
        if _is_slack(g):
            bus_ref = getattr(g, "bus", getattr(g, "node", None))
            if bus_ref is None:
                return None
            bid = str(getattr(bus_ref, "idtag", getattr(bus_ref, "id", getattr(bus_ref, "name", None))))
            if bid in bus_idx_map:
                return bus_idx_map[bid]
            # fallback by name
            if hasattr(bus_ref, "name") and str(bus_ref.name) in bus_idx_map:
                return bus_idx_map[str(bus_ref.name)]
    return None

# ----------- PF / OPF drivers -----------
def run_pf(grid_pf):
    pf_opts = gce.PowerFlowOptions(gce.SolverType.NR, verbose=False)
    _set_val(pf_opts, ["control_taps_modules"], False)
    _set_val(pf_opts, ["control_taps_phase"], False)
    _set_val(pf_opts, ["control_remote_voltage"], False)

    drv = gce.PowerFlowDriver(grid_pf, pf_opts)
    drv.run()
    return drv

def run_opf_teacher(grid_opf, thermal_limits=True):
    # Costs: PV cheap, slack expensive
    for g in getattr(grid_opf, "generators", []):
        _set_val(g, ["active", "in_service"], True)
        if _is_slack(g):
            _set_val(g, ["cost_a"], 1.0)
            _set_val(g, ["is_controlled"], True)  # slack ä¿æŒå¯æ§ï¼ˆå¹³è¡¡èŠ‚ç‚¹ï¼‰
            _set_val(g, ["Pmax", "P_max"], 99999.0)
            _set_val(g, ["Pmin", "P_min"], -99999.0)
        elif _is_sgen(g):
            _set_val(g, ["cost_a"], 0.01)
            # sgen ä¿æŒ PQ + Qé”æ­»ï¼Œåªè®© OPF è°ƒP
            _set_val(g, ["is_controlled"], False)
            _set_val(g, ["enabled_dispatch"], True)

            # ç¡®ä¿Qä»æ˜¯é”æ­»ï¼ˆé˜²æ­¢æœ‰äººæ”¹äº†sceneï¼‰
            lock_Q_as_PQ(g, 0.0)

            # ç¡®ä¿Pminå­˜åœ¨
            _set_val(g, ["Pmin", "P_min"], 0.0)

    opf_opts = gce.OptimalPowerFlowOptions()
    if hasattr(gce, "SolverType"):
        _set_val(opf_opts, ["solver", "solver_type"], gce.SolverType.NONLINEAR_OPF)

    _set_val(opf_opts, ["activate_voltage_limits"], True)
    _set_val(opf_opts, ["activate_thermal_limits"], bool(thermal_limits))
    _set_val(opf_opts, ["dispatch_P"], True)
    _set_val(opf_opts, ["objective"], 0)

    drv = gce.OptimalPowerFlowDriver(grid_opf, opf_opts)
    try:
        drv.run()
    except Exception:
        pass
    return drv

def get_opf_gen_p(opf_driver, grid):
    res = getattr(opf_driver, "results", None)
    if res is not None and hasattr(res, "generator_power"):
        try:
            return [float(v) for v in res.generator_power]
        except Exception:
            pass
    return [_get_float(g, ["P", "p"], 0.0) for g in grid.generators]

# ----------- scene application -----------
def apply_scene_PQ(grid_scene, load_p_row, load_q_row, pav_dict):
    # loads
    for l in getattr(grid_scene, "loads", []):
        lid = _idx_from_name(getattr(l, "name", "load_0"))
        if lid is None:
            continue
        _set_val(l, ["P", "p"], float(load_p_row.get(lid, 0.0)))
        _set_val(l, ["Q", "q"], float(load_q_row.get(lid, 0.0)))

    # generators
    for g in getattr(grid_scene, "generators", []):
        if _is_slack(g):
            _set_val(g, ["active", "in_service"], True)
            _set_val(g, ["is_controlled"], True)
            _set_val(g, ["Pmax", "P_max"], 99999.0)
            _set_val(g, ["Pmin", "P_min"], -99999.0)
            continue

        if _is_sgen(g):
            gid = _idx_from_name(getattr(g, "name", "sgen_0"))
            pav = float(pav_dict.get(gid, 0.0))

            # å…³é”®ï¼šP å’Œ Pmax åˆ†å¼€è®¾ç½®ï¼ˆé¿å…åªè®¾åˆ°Pmaxï¼‰
            _set_val(g, ["P", "p"], pav)
            _set_val(g, ["Pmax", "P_max"], pav)
            _set_val(g, ["Pmin", "P_min"], 0.0)

            # PQ åŒ–
            _set_val(g, ["is_controlled"], False)
            _set_val(g, ["enabled_dispatch"], True)

            # Q é”æ­»
            lock_Q_as_PQ(g, 0.0)

def set_bus_voltage_limits(grid, vmin=0.95, vmax=1.05):
    for b in getattr(grid, "buses", []):
        _set_val(b, ["Vmin"], vmin)
        _set_val(b, ["Vmax"], vmax)

# ----------- build tensor sample -----------
def build_tensor_sample(grid_opf, pf_v_abs, pf_v_angle, opf_gen_p, bus_idx_map, pav_dict):
    num_nodes = len(grid_opf.buses)
    if num_nodes != NUM_NODES:
        return None

    # 5é€šé“: Load P, Load Q, PV_avail(Pmax), V_mag, V_angle
    x = np.zeros((num_nodes, 5), dtype=np.float32)

    # loads
    for l in grid_opf.loads:
        bus_ref = getattr(l, "bus", getattr(l, "node", None))
        if bus_ref is None:
            continue
        bid = str(getattr(bus_ref, "idtag", getattr(bus_ref, "id", getattr(bus_ref, "name", None))))
        idx = bus_idx_map.get(bid, None)
        if idx is None and hasattr(bus_ref, "name"):
            idx = bus_idx_map.get(str(bus_ref.name), None)
        if idx is None:
            continue
        x[idx, 0] += _get_float(l, ["P", "p"], 0.0)
        x[idx, 1] += _get_float(l, ["Q", "q"], 0.0)

    # voltage
    x[:, 3] = pf_v_abs
    x[:, 4] = pf_v_angle

    # generators -> PV avail & labels
    sgen_mask = np.zeros(num_nodes, dtype=bool)
    y_target = np.zeros((num_nodes, 1), dtype=np.float32)

    for i, g in enumerate(grid_opf.generators):
        bus_ref = getattr(g, "bus", getattr(g, "node", None))
        if bus_ref is None:
            continue
        bid = str(getattr(bus_ref, "idtag", getattr(bus_ref, "id", getattr(bus_ref, "name", None))))
        idx = bus_idx_map.get(bid, None)
        if idx is None and hasattr(bus_ref, "name"):
            idx = bus_idx_map.get(str(bus_ref.name), None)
        if idx is None:
            continue

        if _is_sgen(g):
            gid = _idx_from_name(getattr(g, "name", "sgen_0"))
            pav = float(pav_dict.get(gid, 0.0))

            # è¾“å…¥é€šé“ï¼šPV_avail
            x[idx, 2] += pav

            # maskï¼šåªæœ‰ pav è¶³å¤Ÿå¤§æ‰å½“å¯æ§PV
            if pav > SGEN_NODE_THRESHOLD:
                sgen_mask[idx] = True
                popt = float(opf_gen_p[i])
                alpha = np.clip(popt / max(pav, 1e-12), 0.0, 1.0)
                y_target[idx, 0] = alpha

        elif _is_slack(g):
            # slack ä¹Ÿå¯ä»¥æŠŠ Pmax å¡«è¿›é€šé“2ï¼ˆå¯é€‰ï¼‰ï¼Œä½†ä¸è¿›maskã€ä¸å†™y
            x[idx, 2] += 0.0

    # RCM é‡æ’
    x_re = x[PERM_IDX]
    y_re = y_target[PERM_IDX]
    m_re = sgen_mask[PERM_IDX]

    return {
        "x": torch.tensor(x_re.T, dtype=torch.float32),      # (5, N)
        "y": torch.tensor(y_re.T, dtype=torch.float32),      # (1, N)
        "mask": torch.tensor(m_re, dtype=torch.bool)         # (N,)
    }

# ----------- bucket helper -----------
def bucket_of_vmax(vmax):
    if vmax <= V_SAFE:
        return "safe"
    elif vmax <= V_LIMIT:
        return "mid"
    else:
        return "high"

def should_accept_bucket(bucket_counts, total_kept, bucket_name):
    if not USE_BUCKET_SAMPLING:
        return True
    # ç›®æ ‡æ•°ï¼ˆåŠ¨æ€ï¼‰
    targets = {k: int(BUCKET_TARGET[k] * NUM_SAMPLES) for k in BUCKET_TARGET}
    return bucket_counts[bucket_name] < targets[bucket_name]

# ================= main =================
def main():
    os.makedirs(SAVE_DIR, exist_ok=True)
    print(f"ğŸš€ ç”Ÿæˆæ•°æ®ä¸­... ç›®æ ‡: {NUM_SAMPLES}")
    net_pp = sb.get_simbench_net(SB_CODE)
    grid_template = GC_PandaPowerImporter.PP2GC(net_pp)

    # bus idx mapï¼ˆç”¨ idtag / id / name åškeyï¼‰
    bus_idx_map = {}
    for i, b in enumerate(grid_template.buses):
        key = str(getattr(b, "idtag", getattr(b, "id", getattr(b, "name", None))))
        if key is not None:
            bus_idx_map[str(key)] = i
        if hasattr(b, "name") and b.name is not None:
            bus_idx_map[str(b.name)] = i

    profiles = sb.get_absolute_values(net_pp, profiles_instead_of_study_cases=True)
    df_load_p = profiles[("load", "p_mw")]
    df_load_q = profiles[("load", "q_mvar")]
    df_sgen_p = profiles[("sgen", "p_mw")]

    # åªæŒ‘â€œå½“å¤©æ€»PV>é˜ˆå€¼â€çš„æ—¶åˆ»
    valid_ts = [t for t in range(len(df_load_p)) if df_sgen_p.iloc[t].sum() > SGEN_POWER_THRESHOLD]
    if not valid_ts:
        raise RuntimeError("âŒ æ²¡æœ‰æ‰¾åˆ°æ»¡è¶³ PV æ€»å‡ºåŠ›é˜ˆå€¼çš„æ—¶åˆ» valid_ts")

    collected = 0
    chunk_idx = 0
    chunk_buffer = []

    # stats
    sum_x = torch.zeros(5, dtype=torch.float64)
    sq_sum_x = torch.zeros(5, dtype=torch.float64)
    total_pixels = 0

    bucket_counts = {"safe": 0, "mid": 0, "high": 0}

    pbar = tqdm(total=NUM_SAMPLES)

    while collected < NUM_SAMPLES:
        accepted = False
        for _try in range(MAX_TRIES_PER_SAMPLE):
            t = int(np.random.choice(valid_ts))

            # é‡‡æ ·ç¼©æ”¾
            k_global = np.random.uniform(K_GLOBAL_MIN, K_GLOBAL_MAX)
            base_sgen_row = df_sgen_p.iloc[t]

            pav_dict = {}
            for gid, p_base in base_sgen_row.items():
                k_local = np.random.uniform(K_LOCAL_MIN, K_LOCAL_MAX)
                pav_dict[int(gid)] = float(p_base) * k_global * k_local

            # åœºæ™¯ç½‘
            grid_scene = deepcopy(grid_template)
            apply_scene_PQ(grid_scene, df_load_p.iloc[t], df_load_q.iloc[t], pav_dict)
            set_bus_voltage_limits(grid_scene, vmin=0.95, vmax=1.05)
            tighten_thermal_limits(grid_scene, RATE_TIGHTEN_FACTOR)

            # PF
            grid_pf = deepcopy(grid_scene)
            pf_drv = run_pf(grid_pf)
            if not pf_drv.results.converged:
                continue
            V = np.abs(pf_drv.results.voltage)

            # æ’é™¤ slack åçš„ Vmaxï¼ˆé¿å…è¢« slack å›ºå®šç”µå‹å½±å“ï¼‰
            slack_idx = find_slack_bus_idx(grid_pf, bus_idx_map)
            V2 = V.copy()
            if slack_idx is not None and 0 <= slack_idx < len(V2):
                V2[slack_idx] = -1.0
            vmax_wo_slack = float(np.max(V2))

            bname = bucket_of_vmax(vmax_wo_slack)
            if not should_accept_bucket(bucket_counts, collected, bname):
                continue

            pf_v_abs = V.astype(np.float32)
            pf_v_angle = np.angle(pf_drv.results.voltage).astype(np.float32)

            # OPF teacher
            grid_opf = deepcopy(grid_scene)
            opf_drv = run_opf_teacher(grid_opf, thermal_limits=True)
            if not opf_drv.results.converged:
                continue

            opf_gen_p = get_opf_gen_p(opf_drv, grid_opf)

            sample = build_tensor_sample(grid_opf, pf_v_abs, pf_v_angle, opf_gen_p, bus_idx_map, pav_dict)
            if sample is None:
                continue

            # è‡³å°‘è¦æœ‰ä¸€ä¸ªå¯æ§PVèŠ‚ç‚¹
            if sample["mask"].sum().item() == 0:
                continue

            # accept
            bucket_counts[bname] += 1
            accepted = True

            # stats
            sum_x += sample["x"].double().sum(dim=1)
            sq_sum_x += (sample["x"].double() ** 2).sum(dim=1)
            total_pixels += sample["x"].shape[1]

            chunk_buffer.append(sample)
            collected += 1
            pbar.update(1)

            if len(chunk_buffer) >= CHUNK_SIZE:
                torch.save(chunk_buffer, os.path.join(SAVE_DIR, f"chunk_{chunk_idx:05d}.pt"))
                chunk_buffer = []
                chunk_idx += 1

            break

        if not accepted:
            # å¤ªéš¾å‡‘æ»¡æŸä¸ªæ¡¶æ—¶ï¼Œæ”¾å®½ç­–ç•¥ï¼šä¸´æ—¶å…³é—­åˆ†æ¡¶
            if USE_BUCKET_SAMPLING:
                print("âš ï¸ æŸäº›æ¡¶è¿‡éš¾å‡‘æ ·æœ¬ï¼Œä¸´æ—¶æ”¾å®½åˆ†æ¡¶é™åˆ¶ä»¥é¿å…å¡æ­»ã€‚")
                globals()["USE_BUCKET_SAMPLING"] = False

    if chunk_buffer:
        torch.save(chunk_buffer, os.path.join(SAVE_DIR, f"chunk_{chunk_idx:05d}.pt"))

    mean_x = (sum_x / total_pixels).float()
    std_x = torch.sqrt(sq_sum_x / total_pixels - mean_x.double() ** 2).float()
    torch.save({"x_mean": mean_x, "x_std": std_x}, os.path.join(SAVE_DIR, "stats.pt"))

    print("âœ… æ•°æ®ç”Ÿæˆå®Œæ¯•ï¼")
    print("Bucket counts:", bucket_counts)

if __name__ == "__main__":
    main()
