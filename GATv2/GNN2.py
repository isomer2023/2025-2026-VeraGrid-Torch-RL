import torch
import torch.optim as optim
import torch.nn.functional as F
import numpy as np
import simbench as sb
from torch_geometric.data import Data
import warnings
from copy import deepcopy
import csv
import matplotlib.pyplot as plt
import seaborn as sns
import pandas as pd
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
import random
# å¿½ç•¥ Pandas è­¦å‘Š
warnings.filterwarnings('ignore')

# å¯¼å…¥ç¯å¢ƒå’Œå¼•æ“
try:
    import GC_PandaPowerImporter
    from VeraGridEngine import api as gce
    from gnn_model import GridGNN
except ImportError as e:
    print(f"âŒ ç¼ºå°‘ä¾èµ–æ–‡ä»¶: {e}")
    exit()

# ================= é…ç½®å‚æ•° =================
SB_CODE = "1-MV-urban--0-sw"
LR = 0.0005
EPOCHS = 4000
# âœ… [å…³é”®ä¿®æ”¹] å¢å¤§ Batch Sizeï¼Œè®© BatchNorm æ­£å¸¸å·¥ä½œ
BATCH_SIZE = 32
HIDDEN_DIM = 128
HEADS = 4
DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
SAVE_PATH = "best_gnn_model.pth"


# ===========================================

# --- è¾…åŠ©å‡½æ•° ---
def get_gc_id(obj):
    if hasattr(obj, 'id') and obj.id is not None: return obj.id
    if hasattr(obj, 'idtag') and obj.idtag is not None: return obj.idtag
    if hasattr(obj, 'uuid') and obj.uuid is not None: return obj.uuid
    if hasattr(obj, 'name') and obj.name is not None: return obj.name
    return str(obj)


def _set_val(obj, attr_list, val):
    for attr in attr_list:
        try:
            setattr(obj, attr, val);
            return
        except:
            continue


def _get_val(obj, attr_list, default=0.0):
    for attr in attr_list:
        if hasattr(obj, attr):
            try:
                return float(getattr(obj, attr))
            except:
                continue
    return default


def _is_slack_safe(g):
    val = getattr(g, 'is_slack', None)
    if val is not None: return bool(val)
    val = getattr(g, 'slack', None)
    if val is not None: return bool(val)
    name = str(getattr(g, 'name', ''))
    if "Ext_Grid" in name: return True
    return False


def get_safe_gen_results(driver, grid):
    if driver and hasattr(driver, 'results'):
        res = driver.results
        if hasattr(res, 'gen_p') and res.gen_p is not None: return res.gen_p
        if hasattr(res, 'P') and res.P is not None: return res.P
    p_list = []
    for g in grid.generators:
        p_val = _get_val(g, ['P', 'p_mw', 'p'], 0.0)
        p_list.append(p_val)
    return p_list


# --- æ ¸å¿ƒæ¨¡å— ---

def setup_and_run_opf_teacher(grid, current_profile_sgen):
    """ã€è€å¸ˆæ¨¡å—ã€‘"""
    for g in grid.generators:
        g_name = str(getattr(g, 'name', ''))

        if _is_slack_safe(g) or "Ext_Grid" in g_name:
            _set_val(g, ['Pmax', 'P_max'], 99999.0)
            _set_val(g, ['Pmin', 'P_min'], -99999.0)
            _set_val(g, ['cost_a', 'Cost1'], 1.0)
            _set_val(g, ['cost_b', 'Cost2'], 100.0)
            _set_val(g, ['is_controlled', 'controlled'], True)

        elif "sgen" in g_name:
            try:
                sgen_idx = int(g_name.split('_')[1])
                p_avail = current_profile_sgen.get(sgen_idx, 0.0)
            except:
                p_avail = 0.0

            _set_val(g, ['Pmax', 'P_max'], p_avail)
            _set_val(g, ['Pmin', 'P_min'], 0.0)
            _set_val(g, ['cost_a', 'Cost1'], 0.01)
            _set_val(g, ['cost_b', 'Cost2'], 0.1)
            _set_val(g, ['is_controlled', 'controlled'], True)
            _set_val(g, ['Qmax', 'Q_max'], 0.0)
            _set_val(g, ['Qmin', 'Q_min'], 0.0)

    opf_opts = gce.OptimalPowerFlowOptions()
    if hasattr(gce, 'SolverType'):
        _set_val(opf_opts, ['solver', 'solver_type'], gce.SolverType.NONLINEAR_OPF)

    opf_opts.objective = 0
    _set_val(opf_opts, ['activate_voltage_limits', 'voltage_limits'], True)
    _set_val(opf_opts, ['vmin', 'Vmin'], 0.98)
    _set_val(opf_opts, ['vmax', 'Vmax'], 1.02)
    _set_val(opf_opts, ['activate_thermal_limits', 'thermal_limits'], True)
    _set_val(opf_opts, ['dispatch_P', 'control_active_power'], True)
    _set_val(opf_opts, ['dispatch_Q', 'control_reactive_power'], False)
    _set_val(opf_opts, ['allow_soft_limits', 'soft_limits'], True)
    _set_val(opf_opts, ['initialize_with_dc', 'init_dc'], False)

    opf_driver = gce.OptimalPowerFlowDriver(grid, opf_opts)
    try:
        opf_driver.run()
    except:
        pass
    return opf_driver


def get_graph_data(grid, pf_results, bus_idx_map):
    """
    GridCal -> PyG Data
    ä¿®æ­£ç‰ˆï¼š
    1. Node Features: 6ç»´ (å«ç”µå‹ç›¸è§’)
    2. Edge Features: 4ç»´ (Rateé™¤ä»¥1000, Loadingå–ç»å¯¹å€¼, R/Xæ”¾å¤§)
    """
    num_nodes = len(grid.buses)
    x = np.zeros((num_nodes, 6), dtype=np.float32)

    # 1. èŠ‚ç‚¹è´Ÿè· (Load P, Q) -> çœŸå®å€¼ * 3
    for l in grid.loads:
        bus_ref = getattr(l, 'bus', getattr(l, 'node', None))
        if bus_ref:
            idx = bus_idx_map.get(get_gc_id(bus_ref))
            if idx is not None:
                p_val = _get_val(l, ['P', 'p_mw', 'p'])
                q_val = _get_val(l, ['Q', 'q_mvar', 'q'])
                x[idx, 0] += p_val * 3.0
                x[idx, 1] += q_val * 3.0

    # 2. èŠ‚ç‚¹ç”µæº (Gen P) -> çœŸå®å€¼ / 10
    sgen_mask = torch.zeros(num_nodes, dtype=torch.bool)
    for g in grid.generators:
        bus_ref = getattr(g, 'bus', getattr(g, 'node', None))
        if bus_ref:
            idx = bus_idx_map.get(get_gc_id(bus_ref))
            if idx is not None:
                x[idx, 4] = 1.0
                if "sgen" in getattr(g, 'name', ''):
                    p_max = _get_val(g, ['Pmax', 'P_max'], 0.0)
                    x[idx, 2] += p_max / 10.0
                    sgen_mask[idx] = True

    # 3. èŠ‚ç‚¹ç”µå‹ (å¹…å€¼ + ç›¸è§’)
    v_mag_scaled = np.zeros(num_nodes)
    v_ang = np.zeros(num_nodes)
    if pf_results and hasattr(pf_results, 'voltage'):
        v_complex = np.array(pf_results.voltage, dtype=np.complex128)
        if len(v_complex) == num_nodes:
            v_abs = np.abs(v_complex)
            v_mag_scaled = (v_abs - 1.0) * 10.0  # (|V|-1)*10
            v_ang = np.angle(v_complex)  # ç›¸è§’ (å¼§åº¦)

    x[:, 3] = v_mag_scaled
    x[:, 5] = v_ang

    # 4. è¾¹ç‰¹å¾å¤„ç†
    src, dst, attr = [], [], []
    branches = []
    if hasattr(grid, 'branches'):
        branches = grid.branches
    elif hasattr(grid, 'get_branches'):
        branches = grid.get_branches()
    else:
        branches = list(getattr(grid, 'lines', [])) + list(getattr(grid, 'transformers', []))

    branch_loadings = []
    if pf_results and hasattr(pf_results, 'loading'):
        branch_loadings = pf_results.loading

    for i, br in enumerate(branches):
        try:
            if _get_val(br, ['active', 'status'], 1.0) < 0.5: continue
            f_ref = getattr(br, 'bus_from', getattr(br, 'from_node', getattr(br, 'busFrom', None)))
            t_ref = getattr(br, 'bus_to', getattr(br, 'to_node', getattr(br, 'busTo', None)))

            if f_ref and t_ref:
                u = bus_idx_map.get(get_gc_id(f_ref))
                v = bus_idx_map.get(get_gc_id(t_ref))
                if u is not None and v is not None:
                    # åŸå§‹ç‰©ç†å‚æ•°
                    r = float(_get_val(br, ['r', 'R']))
                    x_val = float(_get_val(br, ['x', 'X']))
                    rate = float(_get_val(br, ['rate', 'Rate'], 100.0))

                    loading_val = 0.0
                    if branch_loadings is not None and i < len(branch_loadings):
                        loading_val = float(branch_loadings[i])

                    # =========== å…³é”®ä¿®æ­£ ===========
                    feat_rate = rate / 1000.0  # Rate å½’ä¸€åŒ–
                    feat_load = abs(loading_val)  # Loading å–ç»å¯¹å€¼
                    feat_r = r * 100.0  # æ”¾å¤§ R
                    feat_x = x_val * 100.0  # æ”¾å¤§ X

                    edge_feat = [feat_r, feat_x, feat_rate, feat_load]
                    # ===============================

                    src.extend([u, v])
                    dst.extend([v, u])
                    attr.extend([edge_feat, edge_feat])
        except:
            continue

    x_tensor = torch.tensor(x, dtype=torch.float32).to(DEVICE)
    edge_index = torch.tensor([src, dst], dtype=torch.long).to(DEVICE)
    edge_attr = torch.tensor(attr, dtype=torch.float32).to(DEVICE)
    return Data(x=x_tensor, edge_index=edge_index, edge_attr=edge_attr), sgen_mask.to(DEVICE)

# ================= ä¿®æ­£åçš„è¯„ä¼°å‡½æ•° =================
def evaluate_model(model, grid, bus_idx_map, test_idx, df_load_p, df_load_q, df_sgen_p, device):
    print("\n" + "=" * 40)
    print("ğŸ§ª å¯åŠ¨æµ‹è¯•é›†è¯„ä¼° (Evaluation Phase)")
    print("=" * 40)

    try:
        model.load_state_dict(torch.load("best_gnn_model.pth"))
        print("âœ… å·²åŠ è½½æœ€ä½³æ¨¡å‹æƒé‡: best_gnn_model.pth")
    except Exception as e:
        print(f"âš ï¸ æ— æ³•åŠ è½½æ¨¡å‹æƒé‡ï¼Œå°†ä½¿ç”¨å½“å‰æƒé‡: {e}")

    model.eval()

    # éšæœºé‡‡æ · 1000 ä¸ª
    num_samples = 1000
    if len(test_idx) > num_samples:
        eval_indices = np.random.choice(test_idx, num_samples, replace=False)
    else:
        eval_indices = test_idx

    print(f"ğŸ“Š é‡‡æ ·æ•°é‡: {len(eval_indices)} (æ¥è‡ªæµ‹è¯•é›†)")
    results_list = []

    with torch.no_grad():
        for i, t in enumerate(eval_indices):
            if (i + 1) % 100 == 0:
                print(f"   è¿›åº¦: {i + 1}/{len(eval_indices)}...")

            # --- A. ç¯å¢ƒé‡æ„ ---
            stress_factor = np.random.uniform(6.0, 8.0)

            # è®¾ç½®è´Ÿè·
            current_load_p = df_load_p.iloc[t]
            current_load_q = df_load_q.iloc[t]
            for l in grid.loads:
                try:
                    idx = int(l.name.split('_')[1])
                    _set_val(l, ['P', 'p'], current_load_p.get(idx, 0.0))
                    _set_val(l, ['Q', 'q'], current_load_q.get(idx, 0.0))
                except:
                    pass

            # è®¾ç½®å‘ç”µæœº
            sgen_p_dict = (df_sgen_p.iloc[t] * stress_factor).to_dict()
            grid_pf = deepcopy(grid)
            for g in grid_pf.generators:
                if "sgen" in getattr(g, 'name', ''):
                    try:
                        idx = int(g.name.split('_')[1])
                        p_avail = sgen_p_dict.get(idx, 0.0)
                        _set_val(g, ['Pmax', 'P_max'], p_avail)
                        _set_val(g, ['P', 'p'], p_avail)
                    except:
                        pass

            # --- B. è®¡ç®— Pre-PF ---
            pf_driver = None
            current_pf_results = None
            try:
                pf_opts = gce.PowerFlowOptions(gce.SolverType.NR, verbose=False)
                pf_driver = gce.PowerFlowDriver(grid_pf, pf_opts)
                pf_driver.run()
                current_pf_results = pf_driver.results
            except:
                pass

            # --- C. è®¡ç®— OPF Teacher ---
            teacher_driver = setup_and_run_opf_teacher(grid, sgen_p_dict)
            if not (teacher_driver and hasattr(teacher_driver.results,
                                               'converged') and teacher_driver.results.converged):
                continue

            gen_p_vec = get_safe_gen_results(teacher_driver, grid)

            # --- D. GNN é¢„æµ‹ ---
            data, mask = get_graph_data(grid, current_pf_results, bus_idx_map)
            # data.x çš„å½¢çŠ¶æ˜¯ [num_nodes, features]
            # pred çš„å½¢çŠ¶é€šå¸¸æ˜¯ [num_nodes, 1] æˆ–è€… [num_nodes]
            pred = model(data)

            for g_idx, g in enumerate(grid.generators):
                if "sgen" in getattr(g, 'name', ''):
                    bus = getattr(g, 'bus', getattr(g, 'node', None))
                    if bus:
                        node_idx = bus_idx_map.get(get_gc_id(bus))
                        if node_idx is not None:
                            # 1. è·å–çœŸå€¼ (Teacher)
                            p_opt = float(gen_p_vec[g_idx])
                            p_avail = _get_val(g, ['Pmax', 'P_max'])

                            # 2. è·å–é¢„æµ‹å€¼ (Student) - ç›´æ¥é€šè¿‡èŠ‚ç‚¹ç´¢å¼•æ‹¿
                            pred_val = float(pred[node_idx].item())

                            # 3. è¿‡æ»¤å¹¶ä¿å­˜
                            # æˆ‘ä»¬åªå…³å¿ƒé‚£äº›æœ‰èƒ½åŠ›å‘ç”µçš„æœºç»„
                            if p_avail > 0.001:
                                true_alpha = np.clip(p_opt / p_avail, 0.0, 1.0)
                                # é¢„æµ‹å€¼é€šå¸¸ä¹Ÿéœ€è¦æˆªæ–­åˆ° [0,1] åŒºé—´ä»¥ä¾¿åˆ†æï¼Œè™½ç„¶æ¨¡å‹è¾“å‡ºå¯èƒ½ç•¥å¾®è¶Šç•Œ
                                pred_alpha_clamped = np.clip(pred_val, 0.0, 1.0)

                                results_list.append({
                                    "Time_Step": t,
                                    "Gen_ID": g.name,
                                    "True_Alpha": true_alpha,
                                    "Pred_Alpha": pred_alpha_clamped,
                                    "Error": pred_alpha_clamped - true_alpha,
                                    "Abs_Error": abs(pred_alpha_clamped - true_alpha)
                                })

    df = pd.DataFrame(results_list)
    if df.empty:
        print("âŒ æ²¡æœ‰æ”¶é›†åˆ°æœ‰æ•ˆçš„æµ‹è¯•æ•°æ®ã€‚")
        return

    df.to_csv("eval_results_detailed.csv", index=False)
    print(f"\nâœ… è¯¦ç»†æ•°æ®å·²ä¿å­˜: eval_results_detailed.csv ({len(df)} æ¡è®°å½•)")

    mae = mean_absolute_error(df["True_Alpha"], df["Pred_Alpha"])
    rmse = np.sqrt(mean_squared_error(df["True_Alpha"], df["Pred_Alpha"]))
    r2 = r2_score(df["True_Alpha"], df["Pred_Alpha"])

    print(f"\nğŸ† è¯„ä¼°æŒ‡æ ‡:")
    print(f"   MAE  : {mae:.6f}")
    print(f"   RMSE : {rmse:.6f}")
    print(f"   R2   : {r2:.6f}")

    with open("eval_metrics.txt", "w") as f:
        f.write(f"MAE: {mae}\nRMSE: {rmse}\nR2: {r2}\nSamples: {len(df)}")

    sns.set_theme(style="whitegrid")

    # 1. Scatter
    plt.figure(figsize=(8, 8))
    plt.scatter(df["True_Alpha"], df["Pred_Alpha"], alpha=0.15, s=10, color="#1f77b4")
    plt.plot([0, 1], [0, 1], "r--", linewidth=2, label="Ideal")
    plt.xlabel("Teacher (OPF) Alpha")
    plt.ylabel("Student (GNN) Alpha")
    plt.title(f"Prediction vs Ground Truth (N={len(df)})\nMAE={mae:.4f}, R2={r2:.4f}")
    plt.legend()
    plt.savefig("eval_1_scatter.png", dpi=300)
    plt.close()

    # 2. Hist
    plt.figure(figsize=(10, 6))
    sns.histplot(df["Error"], bins=100, kde=True, color="purple", stat="density")
    plt.axvline(0, color='r', linestyle='--')
    plt.xlabel("Error (Pred - True)")
    plt.title("Error Distribution Histogram")
    plt.savefig("eval_2_error_hist.png", dpi=300)
    plt.close()

    # 3. Boxplot
    plt.figure(figsize=(14, 6))
    gen_errors = df.groupby("Gen_ID")["Abs_Error"].mean().sort_values(ascending=False)
    top_gens = gen_errors.head(30).index
    df_filtered = df[df["Gen_ID"].isin(top_gens)]
    sns.boxplot(x="Gen_ID", y="Abs_Error", data=df_filtered, palette="Reds_r", order=top_gens)
    plt.xticks(rotation=90)
    plt.title("Absolute Error per Generator (Top 30 Worst Controlled)")
    plt.ylabel("Absolute Error")
    plt.tight_layout()
    plt.savefig("eval_3_gen_boxplot.png", dpi=300)
    plt.close()

    print("ğŸ–¼ï¸  æ‰€æœ‰å›¾åƒå·²ç”Ÿæˆ: eval_1_scatter.png, eval_2_error_hist.png, eval_3_gen_boxplot.png")


# å¿…é¡»å¼•å…¥ Batch å·¥å…·
from torch_geometric.data import Batch


def main():
    print(f"ğŸš€ å¯åŠ¨è®­ç»ƒ: {SB_CODE} (Batch={BATCH_SIZE})")

    # 1. å‡†å¤‡æ•°æ®å’Œç¯å¢ƒ
    net_pp = sb.get_simbench_net(SB_CODE)
    grid = GC_PandaPowerImporter.PP2GC(net_pp)
    bus_idx_map = {get_gc_id(b): i for i, b in enumerate(grid.buses)}

    print("ğŸ“¦ åŠ è½½ Profiles...")
    profiles = sb.get_absolute_values(net_pp, profiles_instead_of_study_cases=True)
    df_load_p = profiles[('load', 'p_mw')]
    df_load_q = profiles[('load', 'q_mvar')]
    df_sgen_p = profiles[('sgen', 'p_mw')]

    n_time_steps = len(df_load_p)
    all_idx = np.arange(n_time_steps)
    split1 = int(0.8 * n_time_steps)
    train_idx = all_idx[:split1]
    test_idx = all_idx[split1:]

    # 2. æ¨¡å‹åˆå§‹åŒ–
    model = GridGNN(num_node_features=6, num_edge_features=4,
                    hidden_dim=HIDDEN_DIM, heads=HEADS).to(DEVICE)
    optimizer = optim.Adam(model.parameters(), lr=LR)

    print(f"\n{'Epoch':<6} | {'Loss':<10} | {'Info'}")
    print("-" * 50)

    log_f = open("loss_log.csv", mode="w", newline="", encoding="utf-8")
    log_writer = csv.writer(log_f)
    log_writer.writerow(["epoch", "time_index", "loss"])

    best_loss = float('inf')

    # ã€ä¿®æ”¹ç‚¹ 1ã€‘ åˆ›å»ºä¸€ä¸ªåˆ—è¡¨æ¥æš‚å­˜ Batch æ•°æ®
    batch_data_list = []

    optimizer.zero_grad()  # ç§»åˆ°å¾ªç¯å¤–åˆå§‹åŒ–

    for epoch in range(EPOCHS):
        t = int(np.random.choice(train_idx))

        # --- ç¯å¢ƒç”Ÿæˆ (ä¿æŒä¸å˜) ---
        stress_factor = np.random.uniform(6.0, 8.0)
        current_load_p = df_load_p.iloc[t]
        current_load_q = df_load_q.iloc[t]
        for l in grid.loads:
            try:
                idx = int(l.name.split('_')[1])
                _set_val(l, ['P', 'p'], current_load_p.get(idx, 0.0))
                _set_val(l, ['Q', 'q'], current_load_q.get(idx, 0.0))
            except:
                pass

        sgen_p_dict = (df_sgen_p.iloc[t] * stress_factor).to_dict()
        grid_pf = deepcopy(grid)
        for g in grid_pf.generators:
            if "sgen" in getattr(g, 'name', ''):
                try:
                    idx = int(g.name.split('_')[1])
                    p_avail = sgen_p_dict.get(idx, 0.0)
                    _set_val(g, ['Pmax', 'P_max'], p_avail)
                    _set_val(g, ['P', 'p'], p_avail)
                except:
                    pass

        # --- Pre-PF (ä¿æŒä¸å˜) ---
        pf_driver = None
        current_pf_results = None
        try:
            pf_opts = gce.PowerFlowOptions(gce.SolverType.NR, verbose=False)
            pf_driver = gce.PowerFlowDriver(grid_pf, pf_opts)
            pf_driver.run()
            current_pf_results = pf_driver.results
        except:
            pass

        # --- OPF Teacher (ä¿æŒä¸å˜) ---
        teacher_driver = setup_and_run_opf_teacher(grid, sgen_p_dict)
        if not (teacher_driver and hasattr(teacher_driver.results, 'converged') and teacher_driver.results.converged):
            continue

        gen_p_vec = get_safe_gen_results(teacher_driver, grid)

        # ã€ä¿®æ”¹ç‚¹ 2ã€‘ Target ç”Ÿæˆï¼šéœ€è¦å­˜å‚¨åˆ° CPUï¼Œä¸éœ€è¦ç«‹åˆ»è½¬ GPU
        # æˆ‘ä»¬éœ€è¦ä¸€ä¸ªå…¨é›¶çš„ Target å‘é‡ï¼Œé•¿åº¦ç­‰äºèŠ‚ç‚¹æ•°
        full_target = torch.zeros(len(grid.buses), 1)
        valid_sample = False

        for i, g in enumerate(grid.generators):
            if "sgen" in getattr(g, 'name', ''):
                bus = getattr(g, 'bus', getattr(g, 'node', None))
                if bus:
                    idx = bus_idx_map.get(get_gc_id(bus))
                    if idx is not None:
                        p_opt = float(gen_p_vec[i])
                        p_avail = _get_val(g, ['Pmax', 'P_max'])
                        if p_avail > 0.001:
                            alpha = np.clip(p_opt / p_avail, 0.0, 1.0)
                            full_target[idx] = alpha
                            valid_sample = True

        if not valid_sample: continue

        # --- è·å–å›¾æ•°æ® ---
        # æ³¨æ„ï¼šè¿™é‡Œæˆ‘ä»¬åªè¦ CPU æ•°æ®ï¼Œæœ€å Batch äº†ä¸€èµ·è½¬ GPU
        data, mask = get_graph_data(grid, current_pf_results, bus_idx_map)

        # ã€ä¿®æ”¹ç‚¹ 3ã€‘ å°† target å’Œ mask æŒ‚è½½åˆ° data å¯¹è±¡ä¸Š
        # å› ä¸º Batch() å‡½æ•°ä¼šè‡ªåŠ¨æ‹¼æ¥ data å¯¹è±¡é‡Œçš„å±æ€§ï¼Œåªè¦ç»´åº¦å¯¹å¾—ä¸Š
        data.y_target = full_target  # [Num_Nodes, 1]
        data.mask = mask.cpu()  # [Num_Nodes] (è½¬å› CPU æ–¹ä¾¿ Batch)
        data.to('cpu')  # ç¡®ä¿éƒ½åœ¨ CPU ä¸Š

        batch_data_list.append(data)

        # ã€ä¿®æ”¹ç‚¹ 4ã€‘ çœŸæ­£çš„ Batch è®­ç»ƒé€»è¾‘
        if len(batch_data_list) >= BATCH_SIZE:
            model.train()
            optimizer.zero_grad()

            # A. ç‰©ç†æ‹¼æ¥ï¼šæŠŠ 32 ä¸ªå°å›¾æ‹¼æˆ 1 ä¸ªå¤§å›¾
            # è¿™æ—¶å€™ BatchNorm çœ‹åˆ°çš„æ˜¯ (Num_Nodes * 32) ä¸ªç‚¹ï¼Œç»Ÿè®¡æ•°æ®éå¸¸ç¨³å®š
            big_batch = Batch.from_data_list(batch_data_list).to(DEVICE)

            # B. å‰å‘ä¼ æ’­
            pred = model(big_batch)

            # C. å–å‡ºæ‹¼æ¥åçš„ Target å’Œ Mask
            target_batch = big_batch.y_target.to(DEVICE)
            mask_batch = big_batch.mask.to(DEVICE)

            # D. è®¡ç®— Loss
            if mask_batch.sum() > 0:
                loss = F.smooth_l1_loss(pred[mask_batch], target_batch[mask_batch], beta=0.1)
                loss.backward()

                # æ¢¯åº¦è£å‰ª
                torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)

                optimizer.step()

                # E. è®°å½•å’Œä¿å­˜
                current_loss = loss.item()
                if current_loss < best_loss:
                    best_loss = current_loss
                    torch.save(model.state_dict(), SAVE_PATH)

                print(f"{epoch:<6} | {current_loss:.5f}       | Best: {best_loss:.5f}")
                log_writer.writerow([epoch, t, current_loss])

            # F. æ¸…ç©ºåˆ—è¡¨
            batch_data_list = []

    log_f.close()
    print(f"\nğŸ‰ è®­ç»ƒå®Œæˆï¼å¯åŠ¨è¯„ä¼°...")
    evaluate_model(model, grid, bus_idx_map, test_idx, df_load_p, df_load_q, df_sgen_p, DEVICE)

if __name__ == "__main__":
    main()